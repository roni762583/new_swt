#!/usr/bin/env python3
"""
Phase 3 Validation Script - Shared Inference Engine
Tests the complete inference pipeline to ensure correct integration of:
- Feature processing (Phase 2)
- Checkpoint loading 
- MCTS engine
- Agent factory
- Complete inference pipeline

This validates the COMPLETE system integration ready for production use.
"""

import sys
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import logging
import time
import traceback

# Add the new_swt directory to Python path
sys.path.append(str(Path(__file__).parent))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_complete_inference_pipeline():
    """Test the complete inference pipeline without actual checkpoint files"""
    logger.info("ğŸ§ª Testing Complete Inference Pipeline (Mock Mode)...")
    
    try:
        # Test imports for all critical components
        from swt_core.config_manager import ConfigManager, SWTConfig
        from swt_core.types import AgentType, PositionState, PositionType
        from swt_features.feature_processor import FeatureProcessor, MarketDataPoint
        from swt_inference.inference_engine import InferenceEngine
        from swt_inference.agent_factory import AgentFactory
        from swt_inference.checkpoint_loader import CheckpointLoader
        
        logger.info("âœ… All critical imports successful")
        
        # Test configuration loading
        config_manager = ConfigManager()
        config = config_manager.get_default_config()
        config_manager.force_episode_13475_mode()
        
        logger.info(f"âœ… Configuration loaded: agent={config.agent_system.value}")
        
        # Test feature processor initialization
        feature_processor = FeatureProcessor(config)
        logger.info("âœ… Feature processor initialized")
        
        # Test checkpoint loader initialization  
        checkpoint_loader = CheckpointLoader(config)
        logger.info("âœ… Checkpoint loader initialized")
        
        # Test agent factory
        available_agents = AgentFactory.get_available_agents()
        logger.info(f"âœ… Agent factory ready: {[a.value for a in available_agents]}")
        
        # Test inference engine initialization
        inference_engine = InferenceEngine(config=config)
        logger.info("âœ… Inference engine initialized")
        
        # Test mock market data processing
        base_time = datetime.now()
        base_price = 199.45
        
        logger.info("ğŸ“Š Adding mock market data...")
        for i in range(256):  # Need 256 data points for WST
            price = base_price + 0.01 * np.sin(i * 0.1) + 0.005 * np.random.randn()
            
            data_point = MarketDataPoint(
                timestamp=base_time + timedelta(minutes=i),
                open=price - 0.001,
                high=price + 0.002,
                low=price - 0.002,
                close=price,
                volume=100.0
            )
            
            inference_engine.add_market_data(data_point)
        
        logger.info("âœ… Market data processing successful")
        
        # Test feature processor readiness
        is_ready = inference_engine.feature_processor.is_ready()
        logger.info(f"âœ… Feature processor ready: {is_ready}")
        
        # Test mock inference result creation
        mock_result = inference_engine.create_mock_inference_result(action=2)  # SELL action
        logger.info(f"âœ… Mock inference result: action={mock_result.trading_decision.action}, "
                   f"confidence={mock_result.trading_decision.confidence}")
        
        # Test result validation
        result_dict = mock_result.to_dict()
        assert "trading_decision" in result_dict
        assert "processing_time_ms" in result_dict
        assert result_dict["trading_decision"]["agent_type"] == config.agent_system.value
        logger.info("âœ… Result validation passed")
        
        # Test diagnostics
        flat_position = PositionState()
        diagnostics = inference_engine.get_diagnostics(flat_position, 199.45)
        
        assert "inference_engine" in diagnostics
        assert "features" in diagnostics
        assert "performance" in diagnostics
        logger.info("âœ… Diagnostics generation successful")
        
        # Test performance summary
        performance = inference_engine.get_performance_summary()
        logger.info(f"âœ… Performance summary: {performance}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Complete pipeline test failed: {e}")
        traceback.print_exc()
        return False

def test_episode_13475_compatibility():
    """Test Episode 13475 specific compatibility"""
    logger.info("ğŸ§ª Testing Episode 13475 Compatibility...")
    
    try:
        from swt_core.config_manager import ConfigManager
        from swt_core.types import AgentType
        
        config_manager = ConfigManager()
        config = config_manager.get_default_config()
        
        # Force Episode 13475 mode
        config_manager.force_episode_13475_mode()
        
        # Verify critical Episode 13475 parameters
        compatibility_checks = [
            # MCTS parameters
            (config.trading_config.mcts_config.num_simulations, 15, "MCTS simulations"),
            (config.trading_config.mcts_config.c_puct, 1.25, "MCTS C_PUCT"),
            (config.trading_config.mcts_config.temperature, 1.0, "MCTS temperature"),
            (config.trading_config.mcts_config.discount_factor, 0.997, "MCTS discount"),
            
            # Feature parameters  
            (config.feature_config.wst_J, 2, "WST J parameter"),
            (config.feature_config.wst_Q, 6, "WST Q parameter"),
            (config.feature_config.price_window_size, 256, "Price window size"),
            (config.observation_space.position_state_dim, 9, "Position features dimension"),
            (config.observation_space.market_state_dim, 128, "Market features dimension"),
            
            # Trading parameters
            (config.trading_config.trade_volume, 1, "Trade volume"),
            (config.trading_config.min_confidence, 0.35, "Minimum confidence"),
        ]
        
        failed_checks = []
        for actual, expected, name in compatibility_checks:
            if actual != expected:
                failed_checks.append(f"{name}: expected {expected}, got {actual}")
                
        if failed_checks:
            logger.error("âŒ Episode 13475 compatibility failures:")
            for failure in failed_checks:
                logger.error(f"  - {failure}")
            return False
        
        # Verify agent type
        if config.agent_system != AgentType.STOCHASTIC_MUZERO:
            logger.warning(f"âš ï¸ Agent type is {config.agent_system.value}, expected {AgentType.STOCHASTIC_MUZERO.value}")
        
        logger.info("âœ… Episode 13475 compatibility verified")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Episode 13475 compatibility test failed: {e}")
        traceback.print_exc()
        return False

def test_feature_consistency():
    """Test feature processing consistency between training and live modes"""
    logger.info("ğŸ§ª Testing Feature Processing Consistency...")
    
    try:
        from swt_core.config_manager import ConfigManager
        from swt_core.types import PositionState, PositionType
        from swt_features.feature_processor import FeatureProcessor, MarketDataPoint
        
        config_manager = ConfigManager()
        config = config_manager.get_default_config()
        config_manager.force_episode_13475_mode()
        
        # Initialize two identical processors
        processor1 = FeatureProcessor(config)
        processor2 = FeatureProcessor(config)
        
        # Add identical market data to both
        base_time = datetime.now()
        base_price = 199.45
        
        market_data = []
        for i in range(256):
            price = base_price + 0.01 * np.sin(i * 0.1) + 0.005 * np.random.randn()
            
            data_point = MarketDataPoint(
                timestamp=base_time + timedelta(minutes=i),
                open=price - 0.001,
                high=price + 0.002,
                low=price - 0.002,
                close=price,
                volume=100.0
            )
            market_data.append(data_point)
            
            processor1.add_market_data(data_point)
            processor2.add_market_data(data_point)
        
        # Test with different position states
        position_states = [
            PositionState(),  # Flat
            PositionState(position_type=PositionType.LONG, entry_price=199.20, 
                         bars_since_entry=50, unrealized_pnl_pips=25.0),  # Long
            PositionState(position_type=PositionType.SHORT, entry_price=199.70,
                         bars_since_entry=100, unrealized_pnl_pips=-15.0)  # Short
        ]
        
        consistency_passed = True
        for i, position in enumerate(position_states):
            # Process same observation with both processors
            obs1 = processor1.process_observation(position, 199.45, f"test_{i}")
            obs2 = processor2.process_observation(position, 199.45, f"test_{i}")
            
            # Check consistency
            if not np.allclose(obs1.market_features, obs2.market_features, rtol=1e-10):
                logger.error(f"âŒ Market features inconsistent for position {i}")
                consistency_passed = False
                
            if not np.allclose(obs1.position_features, obs2.position_features, rtol=1e-10):
                logger.error(f"âŒ Position features inconsistent for position {i}")
                consistency_passed = False
                
            if not np.allclose(obs1.combined_features, obs2.combined_features, rtol=1e-10):
                logger.error(f"âŒ Combined features inconsistent for position {i}")
                consistency_passed = False
        
        if consistency_passed:
            logger.info("âœ… Feature processing consistency verified")
            return True
        else:
            logger.error("âŒ Feature processing consistency failed")
            return False
        
    except Exception as e:
        logger.error(f"âŒ Feature consistency test failed: {e}")
        traceback.print_exc()
        return False

def test_mcts_engine_mock():
    """Test MCTS engine functionality with mock components"""
    logger.info("ğŸ§ª Testing MCTS Engine (Mock Mode)...")
    
    try:
        from swt_core.config_manager import ConfigManager
        from swt_core.types import MCTSParameters
        from swt_inference.mcts_engine import MCTSEngine, MCTSVariant, MCTSResult
        
        config_manager = ConfigManager()  
        config = config_manager.get_default_config()
        config_manager.force_episode_13475_mode()
        
        # Test MCTS configuration
        mcts_config = config.trading_config.mcts_config
        
        # Verify Episode 13475 MCTS parameters
        assert mcts_config.num_simulations == 15, f"Expected 15 simulations, got {mcts_config.num_simulations}"
        assert mcts_config.c_puct == 1.25, f"Expected C_PUCT=1.25, got {mcts_config.c_puct}"
        assert mcts_config.temperature == 1.0, f"Expected temperature=1.0, got {mcts_config.temperature}"
        
        logger.info("âœ… MCTS configuration validation passed")
        
        # Test MCTSResult validation
        mock_result = MCTSResult(
            selected_action=2,
            action_probabilities=np.array([0.1, 0.2, 0.4, 0.3], dtype=np.float32),
            visit_counts=np.array([10, 20, 40, 30], dtype=np.float32),
            action_confidence=0.4,
            root_value=0.15,
            policy_logits=np.array([0.05, 0.15, 0.6, 0.2], dtype=np.float32),
            num_simulations=15,
            search_time_ms=75.0,
            algorithm_used="standard"
        )
        
        assert mock_result.validate(), "Mock MCTS result validation failed"
        logger.info("âœ… MCTS result validation passed")
        
        # Test invalid result detection
        invalid_result = MCTSResult(
            selected_action=5,  # Invalid action (> 3)
            action_probabilities=np.array([0.1, 0.2, 0.4, 0.3], dtype=np.float32),
            visit_counts=np.array([10, 20, 40, 30], dtype=np.float32),
            action_confidence=0.4,
            root_value=0.15,
            policy_logits=np.array([0.05, 0.15, 0.6, 0.2], dtype=np.float32),
            num_simulations=15,
            search_time_ms=75.0
        )
        
        assert not invalid_result.validate(), "Invalid MCTS result should fail validation"
        logger.info("âœ… Invalid result detection passed")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ MCTS engine test failed: {e}")
        traceback.print_exc()
        return False

def test_performance_characteristics():
    """Test performance characteristics of the inference system"""
    logger.info("ğŸ§ª Testing Performance Characteristics...")
    
    try:
        from swt_core.config_manager import ConfigManager
        from swt_core.types import PositionState
        from swt_features.feature_processor import FeatureProcessor, MarketDataPoint
        
        config_manager = ConfigManager()
        config = config_manager.get_default_config()
        config_manager.force_episode_13475_mode()
        
        feature_processor = FeatureProcessor(config)
        
        # Performance test setup
        base_time = datetime.now()
        base_price = 199.45
        
        # Test market data ingestion performance
        logger.info("ğŸ“Š Testing market data ingestion performance...")
        
        start_time = time.time()
        for i in range(256):
            price = base_price + 0.01 * np.sin(i * 0.1)
            
            data_point = MarketDataPoint(
                timestamp=base_time + timedelta(minutes=i),
                open=price - 0.001,
                high=price + 0.002,
                low=price - 0.002,
                close=price,
                volume=100.0
            )
            
            feature_processor.add_market_data(data_point)
        
        ingestion_time = (time.time() - start_time) * 1000
        logger.info(f"âœ… Market data ingestion: {ingestion_time:.2f}ms for 256 points")
        
        # Test observation processing performance
        logger.info("ğŸ“Š Testing observation processing performance...")
        
        position = PositionState()
        
        processing_times = []
        for i in range(10):  # Test multiple observations
            start_time = time.time()
            
            observation = feature_processor.process_observation(
                position_state=position,
                current_price=199.45 + 0.01 * i,
                market_cache_key=f"perf_test_{i}"
            )
            
            processing_time = (time.time() - start_time) * 1000
            processing_times.append(processing_time)
            
            # Validate observation
            assert observation.combined_features.shape == (137,), f"Wrong feature shape: {observation.combined_features.shape}"
            assert not np.isnan(observation.combined_features).any(), "Features contain NaN"
            
        avg_processing_time = np.mean(processing_times)
        max_processing_time = np.max(processing_times) 
        min_processing_time = np.min(processing_times)
        
        logger.info(f"âœ… Observation processing performance:")
        logger.info(f"   Average: {avg_processing_time:.2f}ms")
        logger.info(f"   Range: {min_processing_time:.2f}ms - {max_processing_time:.2f}ms")
        
        # Performance requirements check
        if avg_processing_time > 100.0:  # Should be fast for live trading
            logger.warning(f"âš ï¸ Average processing time {avg_processing_time:.2f}ms may be too slow for live trading")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Performance test failed: {e}")
        traceback.print_exc()
        return False

def main():
    """Run all Phase 3 validation tests"""
    logger.info("ğŸš€ Starting Phase 3 Validation - Shared Inference Engine...")
    
    test_results = {
        "complete_pipeline": False,
        "episode_13475_compatibility": False,
        "feature_consistency": False,
        "mcts_engine": False,
        "performance": False
    }
    
    try:
        # Run all validation tests
        test_results["complete_pipeline"] = test_complete_inference_pipeline()
        test_results["episode_13475_compatibility"] = test_episode_13475_compatibility()
        test_results["feature_consistency"] = test_feature_consistency() 
        test_results["mcts_engine"] = test_mcts_engine_mock()
        test_results["performance"] = test_performance_characteristics()
        
        # Summary
        passed_tests = sum(test_results.values())
        total_tests = len(test_results)
        
        logger.info("ğŸ¯ Phase 3 Validation Summary:")
        for test_name, passed in test_results.items():
            status = "âœ… PASS" if passed else "âŒ FAIL"
            logger.info(f"  {status} {test_name.replace('_', ' ').title()}")
        
        logger.info(f"ğŸ“Š Results: {passed_tests}/{total_tests} tests passed")
        
        if passed_tests == total_tests:
            logger.info("ğŸ‰ Phase 3 VALIDATION PASSED - Shared Inference Engine Ready!")
            
            logger.info("ğŸ¯ Phase 3 Achievements:")
            logger.info("  âœ… Complete inference pipeline integrated")
            logger.info("  âœ… Episode 13475 compatibility verified")
            logger.info("  âœ… Feature processing consistency ensured")
            logger.info("  âœ… MCTS engine functionality validated")
            logger.info("  âœ… Performance characteristics acceptable")
            
            logger.info("ğŸš€ READY FOR PRODUCTION DEPLOYMENT!")
            return True
        else:
            logger.error("âŒ Phase 3 validation failed - see errors above")
            return False
        
    except Exception as e:
        logger.error(f"âŒ Phase 3 validation crashed: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)