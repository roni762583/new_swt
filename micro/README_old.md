# ðŸŽ¯ Micro Stochastic MuZero Trading System

## Executive Summary

A **production-grade Stochastic MuZero implementation** for ultra-high-frequency forex trading using streamlined 15-feature inputs. This system solves the critical Hold-only collapse problem through explicit market uncertainty modeling with discrete outcomes and stochastic planning.

### ðŸš€ Key Innovation: Stochastic Market Modeling

Unlike traditional MuZero which assumes deterministic transitions, our implementation models market uncertainty through:
- **3 Discrete Market Outcomes**: UP (>0.5Ïƒ), NEUTRAL (Â±0.5Ïƒ), DOWN (<-0.5Ïƒ)
- **Chance Nodes in MCTS**: Alternating decision/chance layers model market stochasticity
- **Outcome Probability Networks**: Learn to predict market behavior distributions
- **Rolling Standard Deviation**: Adaptive volatility-based thresholds

### ðŸ”¥ Latest Updates (September 2025)

#### Stochastic Implementation (NEW)
- **OutcomeProbabilityNetwork**: Predicts P(UP|s,a), P(NEUTRAL|s,a), P(DOWN|s,a)
- **Modified DynamicsNetwork**: Conditions on discrete outcomes instead of generic z
- **StochasticMCTS**: Tree search through uncertain market scenarios
- **MarketOutcomeCalculator**: Rolling Ïƒ-based outcome classification

#### Clean Reward System
```python
# Immediate, interpretable rewards
BUY/SELL: +1.0    # Reward decisive entry actions
HOLD (in-trade): 0.0     # Neutral during positions
HOLD (idle): -0.05       # Small penalty for inactivity
CLOSE: AMDDP1           # Risk-adjusted P&L evaluation
```

#### Balanced Buffer Management
- **No Priority Replay**: Simple FIFO with quota-based eviction
- **Trade/Hold Balance**: Maintains 30% minimum trading trajectories
- **Clean Eviction**: Oldest-first with category balancing

---

## ðŸ—ï¸ System Architecture

### Neural Networks (5 Core Networks)

#### 1. RepresentationNetwork with Embedded TCN
```python
Input: (batch, 32, 15)  # 32 time steps Ã— 15 features
â”œâ”€â”€ TCN Encoder (48 channels, dilations [1,2,4])
â”œâ”€â”€ Projection (48 â†’ 256)
â”œâ”€â”€ 5 Residual Blocks
â””â”€â”€ Output: (batch, 256) hidden state
```

#### 2. OutcomeProbabilityNetwork (NEW)
```python
Input: Hidden(256) + Action(4)
â”œâ”€â”€ Linear projection (260 â†’ 256)
â”œâ”€â”€ 2 MLPResidualBlocks
â”œâ”€â”€ Outcome head (256 â†’ 3)
â””â”€â”€ Output: Softmax[UP, NEUTRAL, DOWN]
```

#### 3. DynamicsNetwork (MODIFIED)
```python
Input: Hidden(256) + Action(4) + Outcome(3)
â”œâ”€â”€ Linear projection (263 â†’ 256)
â”œâ”€â”€ 3 MLPResidualBlocks
â”œâ”€â”€ Split heads:
â”‚   â”œâ”€â”€ Next state (256)
â”‚   â””â”€â”€ Reward (1)
â””â”€â”€ Output: (next_hidden, reward)
```

#### 4. PolicyNetwork
```python
Input: Hidden(256)
â”œâ”€â”€ 2 MLPResidualBlocks
â”œâ”€â”€ Action head (256 â†’ 4)
â”œâ”€â”€ Temperature scaling
â””â”€â”€ Output: Action logits [HOLD, BUY, SELL, CLOSE]
```

#### 5. ValueNetwork
```python
Input: Hidden(256)
â”œâ”€â”€ 3 MLPResidualBlocks
â”œâ”€â”€ Value head (256 â†’ 601)
â””â”€â”€ Output: Categorical distribution [-300, +300] pips
```

### Stochastic MCTS Tree Structure

```
DecisionNode (Agent selects action)
    â”œâ”€â”€ ChanceNode[HOLD] (Market determines outcome)
    â”‚   â”œâ”€â”€ DecisionNode (UP: +0.5Ïƒ move)
    â”‚   â”œâ”€â”€ DecisionNode (NEUTRAL: Â±0.5Ïƒ)
    â”‚   â””â”€â”€ DecisionNode (DOWN: -0.5Ïƒ move)
    â”œâ”€â”€ ChanceNode[BUY]
    â”‚   â””â”€â”€ ... (3 outcome branches)
    â”œâ”€â”€ ChanceNode[SELL]
    â”‚   â””â”€â”€ ... (3 outcome branches)
    â””â”€â”€ ChanceNode[CLOSE]
        â””â”€â”€ ... (3 outcome branches)
```

### Key Components

**DecisionNode**:
- Prior probability from parent
- Hidden state representation
- UCB-based action selection
- Visit count and value accumulation

**ChanceNode**:
- Market outcome probabilities
- Parent hidden state storage
- Expected value calculation
- Outcome sampling for rollouts

---

## ðŸ“Š Feature Engineering (15 Dimensions)

### 1. Technical Indicators (5)
```python
1. position_in_range_60      # Price position in 60-bar range [0,1]
2. min_max_scaled_momentum_60 # Long-term momentum normalized
3. min_max_scaled_rolling_range # Volatility indicator
4. min_max_scaled_momentum_5  # Short momentum in long context
5. price_change_pips          # Recent price change in pips
```

### 2. Cyclical Time Features (4)
```python
6. dow_cos_final   # Day of week cosine encoding
7. dow_sin_final   # Day of week sine encoding
8. hour_cos_final  # Hour of day cosine encoding
9. hour_sin_final  # Hour of day sine encoding
```

### 3. Position State Features (6)
```python
10. position_side       # Categorical: -1 (short), 0 (flat), 1 (long)
11. position_pips       # Current P&L: tanh(pips/100)
12. bars_since_entry    # Time in position: tanh(bars/100)
13. pips_from_peak      # Distance from best: tanh(pips/100)
14. max_drawdown_pips   # Worst drawdown: tanh(pips/100)
15. accumulated_dd      # Total drawdown area: tanh(accumulated_dd/100)
```

### Data Pipeline
- **Source**: DuckDB with 1M+ minute bars
- **Window**: 32 time steps (32 minutes)
- **Normalization**: Z-score per feature
- **Split**: 70% train / 15% val / 15% test

---

## ðŸŽ® Trading Environment

### Action Space
```python
0: HOLD   # Maintain position or stay flat
1: BUY    # Open long (only when flat)
2: SELL   # Open short (only when flat)
3: CLOSE  # Close position (only when positioned)
```

### Position Management
- **Single Position**: No pyramiding or scaling
- **Clear States**: Flat â†’ Position â†’ Flat
- **Invalid Actions**: -1.0 penalty for illegal moves

### Market Outcome Classification
```python
# Based on rolling standard deviation (20-period)
threshold = 0.5 * rolling_stdev

if price_change > threshold:
    outcome = UP       # Significant upward move
elif price_change < -threshold:
    outcome = DOWN     # Significant downward move
else:
    outcome = NEUTRAL  # Consolidation/noise
```

---

## ðŸ’° Reward System

### Immediate Action Rewards
```python
def calculate_reward(action, position, pnl=None):
    if action == HOLD:
        if position != 0:
            return 0.0      # Neutral during trades
        else:
            return -0.05    # Discourage idle behavior

    elif action in [BUY, SELL]:
        if position == 0:
            return 1.0      # Reward decisive entry
        else:
            return -1.0     # Penalize invalid action

    elif action == CLOSE:
        return calculate_amddp1(pnl)  # Risk-adjusted P&L
```

### AMDDP1 Calculation
- Asymmetric penalties for drawdowns
- Rewards risk-adjusted returns
- Post-trade evaluation only

---

## ðŸš€ Training Configuration

### Model Hyperparameters
```python
# Architecture
input_features: 15
lag_window: 32
hidden_dim: 256
action_dim: 4
num_outcomes: 3        # UP, NEUTRAL, DOWN
support_size: 300      # Value distribution range

# MCTS
num_simulations: 25
depth_limit: 3
dirichlet_alpha: 1.0
exploration_fraction: 0.5

# Optimization
learning_rate: 0.002   # Fixed (no decay)
batch_size: 64
gradient_clip: 1.0
weight_decay: 1e-5
discount: 0.997

# Exploration
initial_temperature: 10.0
final_temperature: 1.0
temperature_decay_episodes: 50000
```

### Experience Buffer
```python
class Experience:
    observation: np.ndarray      # (32, 15)
    action: int                 # 0-3
    policy: np.ndarray          # MCTS policy
    value: float               # MCTS value
    reward: float              # Actual reward
    market_outcome: int        # 0=UP, 1=NEUTRAL, 2=DOWN
    outcome_probs: np.ndarray  # Predicted [P(UP), P(NEUTRAL), P(DOWN)]
    done: bool
```

---

## ðŸ³ Docker Deployment

### Container Configuration
```yaml
# docker-compose.yml
micro-training:
  build:
    context: .
    dockerfile: Dockerfile.micro
  container_name: micro_training
  volumes:
    - ./micro:/workspace/micro
    - ./data:/workspace/data
  environment:
    - PYTHONUNBUFFERED=1
    - CUDA_VISIBLE_DEVICES=""  # CPU-only
  command: python micro/training/train_micro_muzero.py
  mem_limit: 6g
  cpus: "4.0"
```

### Quick Start
```bash
# Clean previous runs
rm -rf micro/checkpoints/*.pth micro/buffer/*

# Build and start training
docker compose up -d --build micro-training

# Monitor progress
docker logs -f micro_training

# Run validation
docker compose up -d micro-validation
```

---

## ðŸ“ˆ Monitoring & Validation

### Key Metrics

#### 1. Action Distribution
```
âœ… Healthy: Mixed actions (25% each Â±10%)
âš ï¸ Warning: >50% single action
ðŸ”´ Critical: >90% single action (collapse)
```

#### 2. Expectancy
```
Formula: (Win% Ã— Avg_Win) - (Loss% Ã— Avg_Loss)
Target: > 0.5 pips per trade
Progress: Negative â†’ Zero â†’ Positive
```

#### 3. Outcome Prediction Accuracy
```
Monitor: Cross-entropy loss on outcomes
Expected: Gradual improvement from 33% (random)
Target: >50% accuracy on next bar direction
```

### Monitoring Tools

```bash
# Comprehensive monitor
/tmp/monitor_stochastic_training.sh

# Real-time metrics
docker logs -f micro_training | grep -E "Episode|Expectancy|Action"

# Validation results
cat micro/validation_results/best_checkpoint.json
```

### Automatic Validation
- Runs every 100 episodes
- 100 episodes on validation data
- Saves best checkpoint based on expectancy
- Tracks win rate and quality score

---

## ðŸ”¬ Testing Suite

### Component Tests
```bash
# Full test suite
python3 micro/tests/test_stochastic_components.py

# Quick integration test
python3 micro/tests/quick_stochastic_test.py
```

### Test Coverage
- Network output shapes and ranges
- Probability distribution validity
- Information flow between components
- MCTS tree structure integrity
- Market outcome calculations
- End-to-end integration

---

## ðŸŽ¯ Problem Solved: Hold-Only Collapse

### The Problem
Deterministic MuZero suffers from:
- Cannot handle market uncertainty
- Learns "inaction is safe"
- Collapses to 100% HOLD
- Zero trading, zero learning

### The Solution
Stochastic planning enables:
- **Uncertainty Reasoning**: Plans through multiple outcomes
- **Expected Value**: Understands positive EV despite uncertainty
- **Natural Exploration**: Chance nodes add variety
- **Adaptive Thresholds**: Responds to changing volatility

### Success Indicators
- Maintained action diversity
- Improving expectancy
- Successful validation trades
- No single-action dominance

---

## ðŸ› ï¸ Troubleshooting

### Common Issues

#### Container Won't Start
```bash
docker ps -a | grep micro_training
docker logs micro_training | tail -50
docker compose down
docker compose up -d --build micro-training
```

#### Slow Training
- Buffer collection: ~10 min for 100 experiences
- Episodes: ~30 sec each (CPU-bound)
- Expected: 100 episodes in ~1 hour

#### Memory Issues
```bash
docker stats micro_training
# Adjust mem_limit in docker-compose.yml
```

---

## ðŸ“ Project Structure

```
micro/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ micro_networks.py         # Neural networks + stochastic
â”‚   â””â”€â”€ tcn_block.py             # TCN implementation
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_micro_muzero.py    # Main training loop
â”‚   â”œâ”€â”€ stochastic_mcts.py       # Stochastic MCTS
â”‚   â””â”€â”€ mcts_micro.py            # Legacy deterministic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ market_outcome_calculator.py  # Outcome classification
â”‚   â””â”€â”€ feature_engineering.py        # Feature computation
â”œâ”€â”€ validation/
â”‚   â””â”€â”€ validate_micro_muzero.py      # Validation script
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_stochastic_components.py # Component tests
â”‚   â””â”€â”€ quick_stochastic_test.py      # Quick check
â”œâ”€â”€ checkpoints/                       # Model saves
â”œâ”€â”€ validation_results/                # Validation outputs
â””â”€â”€ README.md                          # This file
```

---

## ðŸ“Š Performance Benchmarks

### Training Milestones
- **Episode 100**: Buffer filled, training starts
- **Episode 500**: Initial policy emerges
- **Episode 1000**: Outcome predictions improve
- **Episode 5000**: Positive expectancy achieved
- **Episode 10000**: Strategy refinement

### Target Metrics
- **Win Rate**: 45-55% (consistency > accuracy)
- **Expectancy**: >0.5 pips/trade
- **Sharpe Ratio**: >1.0
- **Max Drawdown**: <10%
- **Action Diversity**: No action >40%

---

## ðŸ”„ Version History

### v2.0.0 - Stochastic Implementation (Sept 2025)
- Added OutcomeProbabilityNetwork
- Modified DynamicsNetwork for outcomes
- Implemented StochasticMCTS with chance nodes
- Created MarketOutcomeCalculator
- Fixed Hold-only collapse issue

### v1.5.0 - Clean Rewards (Sept 2025)
- Simplified reward structure
- Removed priority replay
- Added quota-based buffer
- Enhanced exploration parameters

### v1.0.0 - Initial Micro (Sept 2025)
- 15-feature implementation
- TCN-embedded representation
- Basic deterministic MuZero

---

## ðŸ“š References

### Key Files
- `STOCHASTIC_MUZERO_IMPLEMENTATION.md` - Technical deep dive
- `CLAUDE.md` - Development guidelines
- `docker-compose.yml` - Container orchestration

### Concepts
- **MuZero**: Model-based RL with learned dynamics
- **Stochastic MuZero**: Extension for uncertain environments
- **MCTS**: Monte Carlo Tree Search planning
- **AMDDP1**: Asymmetric risk-adjusted returns

---

## âš¡ Quick Commands

```bash
# Fresh start
rm -rf micro/checkpoints/*.pth && docker compose up -d --build micro-training

# Monitor training
docker logs -f micro_training | grep -E "Episode|Action|Expectancy"

# Run validation
docker compose up -d micro-validation

# Check status
/tmp/monitor_stochastic_training.sh

# Stop everything
docker compose down
```

---

**Status**: Production-Ready
**Version**: 2.0.0 (Stochastic)
**Updated**: September 2025
**Maintainer**: Micro Trading Team