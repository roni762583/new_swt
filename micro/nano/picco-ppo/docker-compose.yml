# UNIFIED PRODUCTION DOCKER COMPOSE - PPO NEURAL NETWORK TRAINING
# Single source of truth for all container operations

version: '3.8'

services:
  # ======= MAIN TRAINING SERVICE =======
  ppo-training:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
      cache_from:
        - python:3.11-slim
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: picco-ppo:latest
    container_name: ppo-training
    hostname: ppo-training

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
        reservations:
          cpus: '4'
          memory: 8G

    # Volumes
    volumes:
      - ./checkpoints:/app/checkpoints
      - ./results:/app/results
      - ./numba_cache:/tmp/numba_cache
      - pip-cache:/root/.cache/pip
      - ./env:/app/env  # Mount local env directory to use fixed trading_env.py
      - ./precomputed_features.duckdb:/app/precomputed_features.duckdb:ro  # Mount precomputed features
      - ./master.duckdb:/app/master.duckdb:ro  # Mount local master database
      - ./config.py:/app/config.py:ro  # Mount config file
      - ./train.py:/app/train.py:ro  # Mount training script
      - ./pretrain_zigzag.py:/app/pretrain_zigzag.py  # Mount pretraining script

    # Environment
    environment:
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=8
      - MKL_NUM_THREADS=8
      - NUMBA_NUM_THREADS=8
      - NUMBA_CACHE_DIR=/tmp/numba_cache
      - TZ=America/New_York

    # Command - Skip pretraining, run PPO training directly
    command: >
      bash -c "
      echo 'ðŸš€ Starting PPO training (no pretraining)...' &&
      python -u train.py --timesteps 1000000 --n_envs 4
      "

    # Restart policy
    restart: unless-stopped

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

    # Networks
    networks:
      - ppo-network

  # ======= MONITORING SERVICE =======
  ppo-monitor:
    image: picco-ppo:latest
    container_name: ppo-monitor
    hostname: ppo-monitor

    # Resource limits (lighter)
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

    # Volumes (read-only)
    volumes:
      - ./results:/app/results:ro
      - ./checkpoints:/app/checkpoints:ro
      - ./master.duckdb:/app/master.duckdb:ro  # Mount database for monitoring

    environment:
      - PYTHONUNBUFFERED=1
      - TZ=America/New_York

    # Command
    command: python -u monitor_expectancy.py

    # Dependencies
    depends_on:
      - ppo-training

    restart: unless-stopped

    networks:
      - ppo-network

  # ======= VALIDATION SERVICE =======
  ppo-validation:
    image: picco-ppo:latest
    container_name: ppo-validation
    hostname: ppo-validation

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

    # Volumes
    volumes:
      - ./checkpoints:/app/checkpoints:ro
      - ./results:/app/results
      - ../../../data:/app/data:ro

    environment:
      - PYTHONUNBUFFERED=1
      - TZ=America/New_York

    # Command - validate best checkpoint
    command: >
      bash -c "while true; do
        python -u validate_minimal.py --best;
        sleep 3600;
      done"

    depends_on:
      - ppo-training

    restart: unless-stopped

    networks:
      - ppo-network

  # ======= LIVE TRADING SERVICE =======
  ppo-live:
    image: picco-ppo:latest
    container_name: ppo-live
    hostname: ppo-live

    # Resource limits (production)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

    # Volumes
    volumes:
      - ./checkpoints:/app/checkpoints:ro
      - ./results:/app/results
      - ../../../data:/app/data:ro
      - ./env:/app/env

    environment:
      - PYTHONUNBUFFERED=1
      - TZ=America/New_York
      - LIVE_TRADING=1

    # Command - live trading with best checkpoint
    command: >
      python -u trade_live.py
      --checkpoint checkpoints/best_checkpoint.pth
      --paper-trading

    depends_on:
      - ppo-training

    restart: unless-stopped

    networks:
      - ppo-network

  # ======= TENSORBOARD SERVICE (Optional - adds 1GB) =======
  # Uncomment if you want monitoring dashboard
  # ppo-tensorboard:
  #   image: tensorflow/tensorflow:latest
  #   container_name: ppo-tensorboard
  #   ports:
  #     - "6006:6006"
  #   volumes:
  #     - ./tensorboard:/app/tensorboard:ro
  #     - ./models:/app/models:ro
  #   command: tensorboard --logdir=/app/tensorboard --bind_all --reload_interval=10
  #   networks:
  #     - ppo-network
  #   restart: unless-stopped

networks:
  ppo-network:
    driver: bridge

volumes:
  pip-cache:
    driver: local

# ======= USAGE =======
# Build and start all 4 containers:
#   docker compose up -d --build
#
# Start specific service:
#   docker compose up -d ppo-training
#   docker compose up -d ppo-monitor
#   docker compose up -d ppo-validation
#   docker compose up -d ppo-live
#
# Check status:
#   docker compose ps
#
# Watch logs:
#   docker compose logs -f ppo-training
#   docker compose logs -f ppo-live
#   docker compose logs -f  # All containers
#
# Stop all:
#   docker compose down
#
# Stop and remove volumes:
#   docker compose down -v